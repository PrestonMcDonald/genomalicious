#'
#' hist(
#'     unlist(
#'         apply(genomalicious_PatchyGTs
#'            , 2
#'            , function(i){sum(is.na(i))/length(i)}))
#'     , 100, xlim=c(0,1), main='Guide patchy: Loci', xlab='% missing')
#' par(mfrow=c(1,1))
#'
#'
#' @export
#'
miss_sim_structure <- function(dat_clean, mat_patchy
, sampCol='SAMPLE', locusCol='LOCUS', genoCol='GT'){
# --------------------------------------------+
# Libraries and assertions
# --------------------------------------------+
for(lib in c('data.table', 'tidyr', 'plyr')){ require(lib, character.only=TRUE)}
# Genotype column class
gt_class <- class(dat_clean[[genoCol]])
if(gt_class=='numeric'){
dat_clean[[genoCol]] <- as.integer(dat_clean[[genoCol]])
}
if(gt_class!='character'){
dat_clean[[genoCol]] <- genoscore_converter(dat_clean[[genoCol]])
}
# Check the column arguments are specified
if(sum(length(c(sampCol, locusCol, genoCol) %in% colnames(dat_clean)))!=3){
stop('Required columns not in `dat_clean`: see ?miss_sim_structure')
}
# --------------------------------------------+
# Code
# --------------------------------------------+
# Sampling parameters
nloci <- length(unique(dat_clean[[locusCol]]))
nsamps <- length(unique(dat_clean[[sampCol]]))
# Make a bootstrap missing dataset to have the
# same number of loci and samples as in observed dataset, `dat_clean`
mat_boot <- mat_patchy[
sample(x=1:nrow(mat_patchy), size=nsamps, replace=TRUE)
, sample(x=1:ncol(mat_patchy), size=nloci, replace=TRUE)
]
# The simulated missing dataset:
# Start with the original, convert to a wide format matrix, then
# add in missing values that match positions in `mat_boot`
mat_sim <- DT2Mat_genos(
dat_clean
, sampCol='SAMPLE'
, locusCol='LOCUS'
, genoCol='GT')
mat_sim[which(is.na(mat_boot))] <- './.'
# Convert the simulated dataset back into a long format data table.
# Then subset to only include sample/loci combinations with missing data.
ko_genos <- DT2Mat_genos(
mat_sim
, sampCol=sampCol
, locusCol=locusCol
, genoCol=genoCol
, flip=TRUE)[GT=='./.']
# Make a copy of the clean dataset
dat_sim <- copy(dat_clean)
# Unique identifiers for each sample/locus combination in the
# simulated and observed datasets
ko_genos$SAMPLE.LOCUS <- paste(ko_genos$SAMPLE, ko_genos$LOCUS, sep='/')
dat_sim$SAMPLE.LOCUS <- paste(dat_sim[[sampCol]], dat_sim[[locusCol]], sep='/')
# Get the index of the missing sample/loci combinations in the
# observed dataset, then knock 'em out.
ko_indx <- match(ko_genos$SAMPLE.LOCUS, dat_sim$SAMPLE.LOCUS)
dat_sim[ko_indx, genoCol] <- './.'
# Convert genotypes back to integer if that was the original specification
if(gt_class %in% c('numeric', 'integer')){
dat_clean[[genoCol]] <- genoscore_converter(dat_clean[[genoCol]])
}
# Return
return(dat_sim)
}
#' @examples
#' library(data.table)
#' data(genomalicious_PatchyGTs)
#' data(genomalicious_4pops)
#'
#' # Take a look at the patchy dataset
#' genomalicious_PatchyGTs
#'
#' # Simulate missing data structure
#' patchy4pops <- miss_sim_structure(
#'     dat_clean=genomalicious_4pops
#'     , mat_patchy=genomalicious_PatchyGTs
#'     , sampCol='SAMPLE'
#'     , locusCol='LOCUS'
#'     , genoCol='GT'
#' )
#'
#' # Take a look at the output.
#' # Histograms are ordered with samples in the first
#' # row and loci in the second row. The first column
#' # is the observed clean data, the second column
#' # is the simulated missing data, and the thir column
#' # is the missing data in the patchy guide matrix.
#' par(mfrow=c(2,3))
#' hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
#'     , 100, xlim=c(0,1), main='Obs clean: Samples', xlab='% missing')
#'
#' hist(patchy4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
#'     , 100, xlim=c(0,1), main='Sim patchy: Samples', xlab='% missing')
#'
#' hist(
#'     unlist(
#'         apply(genomalicious_PatchyGTs
#'            , 1
#'            , function(i){sum(is.na(i))/length(i)}))
#'     , 100, xlim=c(0,1), main='Guide patchy: Samples', xlab='% missing')
#'
#' hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
#'     , 100, xlim=c(0,1), main='Obs clean: Loci', xlab='% missing')
#'
#' hist(patchy4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
#'     , 100, xlim=c(0,1), main='Sim patchy: Loci', xlab='% missing')
#'
#' hist(
#'     unlist(
#'         apply(genomalicious_PatchyGTs
#'            , 2
#'            , function(i){sum(is.na(i))/length(i)}))
#'     , 100, xlim=c(0,1), main='Guide patchy: Loci', xlab='% missing')
#' par(mfrow=c(1,1))
library(data.table)
data(genomalicious_PatchyGTs)
data(genomalicious_4pops)
# Take a look at the patchy dataset
genomalicious_PatchyGTs
# Simulate missing data structure
patchy4pops <- miss_sim_structure(
dat_clean=genomalicious_4pops
, mat_patchy=genomalicious_PatchyGTs
, sampCol='SAMPLE'
, locusCol='LOCUS'
, genoCol='GT'
)
# Take a look at the output.
# Histograms are ordered with samples in the first
# row and loci in the second row. The first column
# is the observed clean data, the second column
# is the simulated missing data, and the thir column
# is the missing data in the patchy guide matrix.
par(mfrow=c(2,3))
hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
, 100, xlim=c(0,1), main='Obs clean: Samples', xlab='% missing')
hist(patchy4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
, 100, xlim=c(0,1), main='Sim patchy: Samples', xlab='% missing')
hist(
unlist(
apply(genomalicious_PatchyGTs
, 1
, function(i){sum(is.na(i))/length(i)}))
, 100, xlim=c(0,1), main='Guide patchy: Samples', xlab='% missing')
hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
, 100, xlim=c(0,1), main='Obs clean: Loci', xlab='% missing')
hist(patchy4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
, 100, xlim=c(0,1), main='Sim patchy: Loci', xlab='% missing')
hist(
unlist(
apply(genomalicious_PatchyGTs
, 2
, function(i){sum(is.na(i))/length(i)}))
, 100, xlim=c(0,1), main='Guide patchy: Loci', xlab='% missing')
par(mfrow=c(1,1))
library(data.table)
data(genomalicious_PatchyGTs)
data(genomalicious_4pops)
# Take a look at the patchy dataset
genomalicious_PatchyGTs
# Simulate missing data structure
patchy4pops <- miss_sim_structure(
dat_clean=genomalicious_4pops
, mat_patchy=genomalicious_PatchyGTs
, sampCol='SAMPLE'
, locusCol='LOCUS'
, genoCol='GT'
)
library(genomalicious)
patchy4pops <- miss_sim_structure(
dat_clean=genomalicious_4pops
, mat_patchy=genomalicious_PatchyGTs
, sampCol='SAMPLE'
, locusCol='LOCUS'
, genoCol='GT'
)
par(mfrow=c(2,3))
hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
, 100, xlim=c(0,1), main='Obs clean: Samples', xlab='% missing')
hist(patchy4pops[, sum(GT=='./.')/length(GT), by=SAMPLE]$V1
, 100, xlim=c(0,1), main='Sim patchy: Samples', xlab='% missing')
hist(
unlist(
apply(genomalicious_PatchyGTs
, 1
, function(i){sum(is.na(i))/length(i)}))
, 100, xlim=c(0,1), main='Guide patchy: Samples', xlab='% missing')
hist(genomalicious_4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
, 100, xlim=c(0,1), main='Obs clean: Loci', xlab='% missing')
hist(patchy4pops[, sum(GT=='./.')/length(GT), by=LOCUS]$V1
, 100, xlim=c(0,1), main='Sim patchy: Loci', xlab='% missing')
hist(
unlist(
apply(genomalicious_PatchyGTs
, 2
, function(i){sum(is.na(i))/length(i)}))
, 100, xlim=c(0,1), main='Guide patchy: Loci', xlab='% missing')
par(mfrow=c(1,1))
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
roxygenise()
X <- genomalicious_PoolReads[grep(pattern='Rep1', x=genomalicious_PoolReads$SAMPLE)]
library(genomalicious)
data(genomalicious_PoolInfo)
data(genomalicious_PoolReads)
X <- genomalicious_PoolReads[grep(pattern='Rep1', x=genomalicious_PoolReads$SAMPLE)]
X
X$POOL <- unlist(lapply(strsplit(X$SAMPLE, '_'), function(X){ return(X[1]) }))
dat <- X
pool.info <- genomalicious_PoolInfo
# --------------------------------------------+
# Libraries and assertions
# --------------------------------------------+
for(i in c('tidyr', 'data.table', 'poolfstat')){ require(i, character.only=TRUE); rm(i)}
if(sum(c('CHROM', 'POS', 'REF', 'ALT', 'LOCUS', 'POOL', 'AO', 'RO') %in% colnames(dat)) != 8){
stop('Argument dat needs the columns $CHROM, $POS, $REF, $ALT, $LOCUS, $POOL, $AO, and $RO.')
}
if(sum(c('POOL', 'INDS') %in% colnames(pool.info)) != 2){
stop('Argument pool.info needs the columns $POOL and $INDS.')
}
if(sum(unique(dat$POOL) %in% pool.info$POOL) != length(unique(dat$POOL))){
stop('The pools in argument dat are not all present in argument pool.info.')
}
setorderv(dat, cols=c('LOCUS', 'POOL'))
setorder(pool.info, POOL)
aoMat <- spread(data=dat[, c('LOCUS', 'POOL', 'AO')], key=POOL, value=AO)
roMat <- spread(data=dat[, c('LOCUS', 'POOL', 'RO')], key=POOL, value=RO)
loci <- dat[, c('CHROM', 'POS', 'REF', 'ALT')]; loci <- loci[!duplicated(loci),]
aoMat
X <- new("pooldata")
X@npools <- length(unique(dat$POOL))
X@nsnp <- nrow(loci)
X@refallele.readcount <- as.matrix(roMat[, !'LOCUS'], rownames=roMat$LOCUS)
X
dat
dat$DP <- dat$AO + dat$RO
dpMat <- spread(data=dat[, c('LOCUS', 'POOL', 'DP')], key=POOL, value=DP)
dpMat
dpMat <- spread(data=dat[, c('LOCUS', 'POOL', 'DP')], key=POOL, value=DP)
roMat <- spread(data=dat[, c('LOCUS', 'POOL', 'RO')], key=POOL, value=RO)
loci <- dat[, c('CHROM', 'POS', 'REF', 'ALT')]; loci <- loci[!duplicated(loci),]
X <- new("pooldata")
X@npools <- length(unique(dat$POOL))
X@nsnp <- nrow(loci)
X@refallele.readcount <- as.matrix(roMat[, !'LOCUS'], rownames=roMat$LOCUS)
X@readcoverage <- as.matrix(dpMat[, !'LOCUS'], rownames=dpMat$LOCUS)
X@snp.info <- as.matrix(loci)
X@poolsizes <- pool.info[which(pool.info$POOL %in% colnames(dpMat[, !'LOCUS']))]$INDS * 2
X@poolnames <- pool.info[which(pool.info$POOL %in% colnames(dpMat[, !'LOCUS']))]$POOL
Fst=computeFST(X, method=method, snp.index=snp.index)
#' Calculate FST with \code{poolfstat} from a data table of read counts
#'
#' Takes a data table of read counts and creates an object of class
#' \code{poolfstat}. The FST for the pools in the data table is calculated using
#' the function \code{poolfstat::computeFST}. Also requires pool size information.
#'
#' @param dat Data table: Contains read counts, e.g. like that been
#' produced by the function \code{vcf2DT}. Must contain all the following columns:
#' \enumerate{
#'    \item \code{$CHROM} The chromosome (contig) ID.
#'    \item \code{$POS} The variant position on the chromosome.
#'    \item \code{$REF} The reference allele.
#'    \item \code{$ALT} The alternate allele.
#'    \item \code{$LOCUS} The locus ID.
#'    \item \code{$POOL} The pool ID.
#'    \item \code{$AO} The number of reads supporting the alternate allele.
#'    \item \code{$RO} The number of reads supporting the reference allele.
#' }
#'
#' @param pool.info Data table: Contains the sample sample sizes (number of diploids) for
#' for each unique pool listed in \code{dat$POOL}. Requires two columns:
#' \enumerate{
#'    \item \code{$POOL} The pools listed in \code{dat$POOL}.
#'    \item \code{$INDS} The number of diploid individuals for the pools.
#' }
#'
#' @param method Character: Either 'Anova' (default) or 'Identity'. Passed to \code{method} argument
#' in \code{poolfstat::computeFST}.
#'
#' @param snp.index List: A list of SNPs to consider. Default = \code{NA}.
#' Passed to \code{snp.index} argument in \code{poolfstat::computeFST}.
#'
#' @return Returns a list with two indices: \code{$Fst} is the calculated FST among the
#' pools using a function call of \code{poolfstat::computeFST}, whereas \code{$pooldat} is the
#' \code{poolfstat} object used to generate said FST values.
#'
#' @examples
#' # Load in the pool metadata and reads
#' data(genomalicious_PoolInfo)
#' data(genomalicious_PoolReads)
#'
#' # Subset to keep only Rep1 reads.
#' X <- genomalicious_PoolReads[grep(pattern='Rep1', x=genomalicious_PoolReads$SAMPLE)]
#'
#' # Need to add pool ID.
#' X$POOL <- unlist(lapply(strsplit(X$SAMPLE, '_'), function(X){ return(X[1]) }))
#'
#' # Calculate FST using poolfstat
#' Y <- poolfstat_DT(X, genomalicious_PoolInfo)
#'
#' # Output is a list
#' class(Y)
#'
#' # Outout from poolfstat::computeFST
#' Y$Fst
#'
#' # The pooldata class object, generated from data table of pooled reads
#' class(Y$pooldat)
#' Y$pooldat
#'
#'@export
poolfstat_DT <- function(dat, pool.info, method='Anova', snp.index=NA){
# --------------------------------------------+
# Libraries and assertions
# --------------------------------------------+
for(i in c('tidyr', 'data.table', 'poolfstat')){ require(i, character.only=TRUE); rm(i)}
if(sum(c('CHROM', 'POS', 'REF', 'ALT', 'LOCUS', 'POOL', 'AO', 'RO') %in% colnames(dat)) != 8){
stop('Argument dat needs the columns $CHROM, $POS, $REF, $ALT, $LOCUS, $POOL, $AO, and $RO.')
}
if(sum(c('POOL', 'INDS') %in% colnames(pool.info)) != 2){
stop('Argument pool.info needs the columns $POOL and $INDS.')
}
if(sum(unique(dat$POOL) %in% pool.info$POOL) != length(unique(dat$POOL))){
stop('The pools in argument dat are not all present in argument pool.info.')
}
setorderv(dat, cols=c('LOCUS', 'POOL'))
setorder(pool.info, POOL)
dat$DP <- dat$AO + dat$RO
dpMat <- spread(data=dat[, c('LOCUS', 'POOL', 'DP')], key=POOL, value=DP)
roMat <- spread(data=dat[, c('LOCUS', 'POOL', 'RO')], key=POOL, value=RO)
loci <- dat[, c('CHROM', 'POS', 'REF', 'ALT')]; loci <- loci[!duplicated(loci),]
X <- new("pooldata")
X@npools <- length(unique(dat$POOL))
X@nsnp <- nrow(loci)
X@refallele.readcount <- as.matrix(roMat[, !'LOCUS'], rownames=roMat$LOCUS)
X@readcoverage <- as.matrix(dpMat[, !'LOCUS'], rownames=dpMat$LOCUS)
X@snp.info <- as.matrix(loci)
X@poolsizes <- pool.info[which(pool.info$POOL %in% colnames(dpMat[, !'LOCUS']))]$INDS * 2
X@poolnames <- pool.info[which(pool.info$POOL %in% colnames(dpMat[, !'LOCUS']))]$POOL
return(list(Fst=computeFST(X, method=method, snp.index=snp.index), pooldat=X))
rm(X)
}
Y <- poolfstat_DT(X, genomalicious_PoolInfo)
X
data(genomalicious_PoolInfo)
data(genomalicious_PoolReads)
# Subset to keep only Rep1 reads.
X <- genomalicious_PoolReads[grep(pattern='Rep1', x=genomalicious_PoolReads$SAMPLE)]
# Need to add pool ID.
X$POOL <- unlist(lapply(strsplit(X$SAMPLE, '_'), function(X){ return(X[1]) }))
Y <- poolfstat_DT(X, genomalicious_PoolInfo)
Y
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
#' Simulate observed allele frequencies
#'
#' Used to generate a simulated distribution of Ref allele frequencies. Takes the
#' output of \code{poolne_estim}, a programme by Gautier et al. (2013).
#' The output is a list, where each indexed item is a data table for each locus;
#' these data tables contain simulated Ref allele frequencies for each population pool
#' based on their pi and sd (as estimated by \code{poolne_estim}).
#'
#' @param dat Data table: the \code{poolne_estim} data. For example, the
#' output from \code{genomalicious::poolne_estim_output()}. Requires 4 columns: \cr
#' \enumerate{
#'    \item \code{$POOL}, the population pool ID. \cr
#'    \item \code{$LOCUS}, the locus ID. \cr
#'    \item \code{$PI}, the estimated population frequency for the Ref allele. \cr
#'    \item \code{$SD}, the standard deviation for PI.
#' }
#'
#' @param num.sims Numeric, the number of simulations to generate. Default = \code{100}.
#'
#' @return A data table, with the following columns:
#' \enumerate{
#'    \item \code{$POOL}, the population pool ID. \cr
#'    \item \code{$LOCUS}, the locus ID. \cr
#'    \item \code{$SIM.NUM}, the simulation number. \cr
#'    \item \code{$SIM.PI}, the simulated pi (Ref allele frequency).
#' }
#'
#' @details The values of \code{PI} and \code{SD} in \code{dat} are used to generate
#' the alpha and beta paramters of a beta distribution, where: \cr
#' \cr
#' \code{alpha = ((1 - Mu) / Var - 1 / Mu) * Mu ^ 2} \cr
#' \code{beta = alpha * (1 / Mu - 1)} \cr
#' \cr
#' Here, values of \code{dat$PI} take on the values of \code{Mu} (the mean) and
#' \code{(dat$SD)^2} take on the values of \code{Var} (the variance). \cr
#' \cr
#' From the resulting beta distribution, \code{num.sims} values are drawn to create
#' a distribution of possible allele frequencies (for each locus) that might exist in the sampled
#' populations (given the associated mean and error estimated by \code{poolne_estim}).
#'
#' @examples
#' # Create a link to raw external datasets in genomalicious
#' genomaliciousExtData <- paste0(find.package('genomalicious'), '/extdata')
#'
#' # Get the poolne estimat pi estimates
#' pi.data <- poolne_estim_output(stat='pi', datDir=genomaliciousExtData, lociDir=genomaliciousExtData)
#'
#' # Simulate potential distributions
#' pi.sims <- poolne_estim_sim_pi(pi.data, 100)
#' pi.sims
#'
#' @export
poolne_estim_sim_pi <- function(dat, num.sims=100){
# BEGIN ...................
# --------------------------------------------+
# Libraries and assertions
# --------------------------------------------+
for(lib in c('data.table', 'pbapply')){ require(lib, character.only=TRUE)}
# Check the class of dat.
if(!'data.table' %in% class(dat)){
stop("Argument dat needs to be class 'data.table'.")
}
# Check that the correct columns are in dat.
if(length(which((c('POOL', 'LOCUS', 'PI', 'SD') %in% colnames(dat))==FALSE)) > 0){
stop("Argument dat needs the columns $POOL, $LOCUS, $PI, and $SD.")
}
# --------------------------------------------+
# Internal function
# --------------------------------------------+
beta_est <- function(Mu, Var) {
# Estimates beta distribution shape params from the mean and variance of
# a sample.
#
# INPUTS:
#   Mu    (numeric)   The sample mean
#   Var   (numeric)   The sample variance
#
# OUTPUTS:
#   A list: $alpha = alpha param, $beta = beta param
# BEGIN ............
alpha <- ((1 - Mu) / Var - 1 / Mu) * Mu ^ 2
beta <- alpha * (1 / Mu - 1)
return(params = list(alpha = alpha, beta = beta))
# ............ END
}
# --------------------------------------------+
# Code
# --------------------------------------------+
# Get index for PI and SD
index.pi <- which(names(dat)=='PI'); index.sd <- which(names(dat)=='SD')
# Split the dataset on LOCUS
dat.spl <- split(dat, dat$LOCUS)
# This function works on each LOCUS
cat('Conducting parametric bootstrap on observed frequencies', sep='\n')
freq.sims <- pblapply(dat.spl, function(W){
# This function work on each POOL (i.e. the rows). Subset W so it only contains
# PI (columns = 1) and SD (column = 2)
Y <- apply(W[,c('POOL','LOCUS','PI','SD')], 1, function(X){
# Calculate the beta shape params (alpha and beta) from PI and SD (square SD to
# make it into variance).
beta.params <- beta_est(as.numeric(X['PI']), as.numeric(X['SD'])^2)
# Generate a vector of length num.sims of pi values from a beta distribution
# using the calculated shape params
pi.sims <- rbeta(num.sims, beta.params$alpha, beta.params$beta)
# Return the vector of simulated pi values.
return(data.table(POOL=X['POOL'], LOCUS=X['LOCUS']
, SIM.NUM=1:num.sims, SIM.PI=pi.sims))
})
# Return locus simulations
return(do.call('rbind', Y))
})
# Return final dataset
return(do.call('rbind', freq.sims))
# ................... END
}
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyr')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
