if(keepInfo==TRUE){
vcfInfo <- vcfDT$INFO
names(vcfInfo) <- vcfDT$LOCUS
}
vcfDT <- vcfDT[, !'INFO']
# Which columns are the sample? The ones after the FORMAT column.
sampCols <- (which(colnames(vcfDT)=='FORMAT')+1):ncol(vcfDT)
# Now convert the data from wide to long
cat('(3/4) Converting from wide to long format', sep='\n')
vcfDT <- melt(data=vcfDT, id.vars=1:(sampCols[1]-1), measure.vars=sampCols, variable.name='SAMPLE', value.name='DATA')
# Make sure SAMPLE is a character
vcfDT$SAMPLE <- as.character(vcfDT$SAMPLE)
# Add the $FORMAT data into the data table
cat('(4/4) Collecting and organising FORMAT data', sep='\n')
if(numCores==1){
# Split string for each row, this will return a wide DT so
# transpose back into long DT.
formatDat <- t(vcfDT[, strsplit(DATA, ':')])
# Give missing values NA
formatDat[which(formatDat=='.')] <- NA
# Label the columns
colnames(formatDat) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
# Combine with the main data table, drop the $FORMAT and $DATA columns
vcfDT <- cbind(vcfDT[, !c('FORMAT','DATA'), with=FALSE], as.data.table(formatDat))
} else if(numCores>1){
# Register the number of cores for parallel processing
clust <- makeCluster(numCores)
registerDoParallel(cl=clust)
# The start position of the data chunks
chunkSt <- seq(1, nrow(vcfDT), by=numChunks)
# The max number of rows
maxRows <- nrow(vcfDT)
# Make row IDs
vcfDT[, ROW.ID:=1:nrow(vcfDT)]
# Iterate over the chunks
formatDat <- foreach(i=chunkSt, .combine='rbind') %dopar% {
require(data.table); require(tidyverse)
i2j <- i:(i + numChunks - 1)
i2j <- i2j[i2j<=maxRows]
xx <- vcfDT[i2j,]
yy <- t(xx[, strsplit(DATA, ':')])
yy[which(yy=='.')] <- NA
colnames(yy) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
yy <- as.data.table(yy)
yy$ROW.ID <- i2j
yy
}
# End cluster
stopCluster(clust)
# Combine data table and the parsed format data
vcfDT <- left_join(
vcfDT[, !c('FORMAT','DATA'), with=FALSE]
, formatDat, by='ROW.ID') %>%
.[, !'ROW.ID']
}
# Make sure DP, RO, and AO are integers
for(i in c('DP', 'RO', 'AO')){
if(i %in% colnames(vcfDT)){ vcfDT[[i]] <- as.integer(vcfDT[[i]]) }
}
# Attach header as an attribute, if specified.
if(keepComments==TRUE){
attr(vcfDT, 'vcf_comments') <- readLines(vcfFile, n=headPos-1)
}
# Attach info as an attribute if, if specified.
if(keepInfo==TRUE){
attr(vcfDT, 'vcf_info') <- vcfInfo
}
# Finish
cat('All done! <3', '\n')
# Return the data.table, drop any columns if specified.
if(is.null(dropCols)){
return(vcfDT)
} else{
return(vcfDT[, !dropCols, with=FALSE])
}
)vcfDT
vcfDT
attributes*vcfDT
attributes(vcfDT)
genomaliciousExtData <- paste0(find.package('genomalicious'), '/extdata')
# This command here shows you the VCF file that comes with genomalicious
list.files(path=genomaliciousExtData, pattern='indseq.vcf')
# Use this to create a path to that file
vcfPath <- paste0(genomaliciousExtData, '/data_indseq.vcf')
# You can read the file in as lines to see what it
# looks like:
readLines(vcfPath)
# Now read it in as a data table
readVcf1 <- vcf2DT(vcfFile=vcfPath)
readVcf1
# Read in VCF, but drop some columns,
# and keep comments and info.
readVcf2 <- vcf2DT(vcfPath
, dropCols=c('FILTER', 'ID')
, keepComments=TRUE
, keepInfo=TRUE)
readVcf2
attr(readVcf2, 'vcf_comments')
attr(readVcf2, 'vcf_info')
# Run in parallel
readVcf3 <- vcf2DT(vcfPath
, numCores=2
, numChunks=10)
genomaliciousExtData <- paste0(find.package('genomalicious'), '/extdata')
list.files(path=genomaliciousExtData, pattern='indseq.vcf')
vcfPath <- paste0(genomaliciousExtData, '/data_indseq.vcf')
readLines(vcfPath)
readVcf1 <- vcf2DT(vcfFile=vcfPath)
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# #### Libraries and assertions            ####
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
require(data.table); require(doParallel); require(tidyverse)
# What is the position of the header?
headPos <- grep('#CHROM', readLines(vcfFile), value=FALSE)
# Read file from header
cat('(1/4) Reading in VCF as a data table', sep='\n')
vcfDT <- fread(vcfFile, skip=headPos-1, sep='\t', header=TRUE)
# Adjust header
colnames(vcfDT) <- gsub(pattern='#', replace='', x=colnames(vcfDT))
vcfDT <- vcfDT[, paste(CHROM, POS, sep='_')] %>%
data.table(LOCUS=., vcfDT)
# Get the locus info as a vector and drop from data table
if(keepInfo==TRUE){
vcfInfo <- vcfDT$INFO
names(vcfInfo) <- vcfDT$LOCUS
}
# Which columns are the sample? The ones after the FORMAT column.
sampCols <- (which(colnames(vcfDT)=='FORMAT')+1):ncol(vcfDT)
vcfDT <- melt(data=vcfDT, id.vars=1:(sampCols[1]-1), measure.vars=sampCols, variable.name='SAMPLE', value.name='DATA')
# Make sure SAMPLE is a character
vcfDT$SAMPLE <- as.character(vcfDT$SAMPLE)
# Add the $FORMAT data into the data table
cat('(4/4) Collecting and organising FORMAT data', sep='\n')
if(numCores==1){
# Split string for each row, this will return a wide DT so
# transpose back into long DT.
formatDat <- t(vcfDT[, strsplit(DATA, ':')])
# Give missing values NA
formatDat[which(formatDat=='.')] <- NA
# Label the columns
colnames(formatDat) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
# Combine with the main data table, drop the $FORMAT and $DATA columns
vcfDT <- cbind(vcfDT[, !c('FORMAT','DATA'), with=FALSE], as.data.table(formatDat))
} else if(numCores>1){
# Register the number of cores for parallel processing
clust <- makeCluster(numCores)
registerDoParallel(cl=clust)
# The start position of the data chunks
chunkSt <- seq(1, nrow(vcfDT), by=numChunks)
# The max number of rows
maxRows <- nrow(vcfDT)
# Make row IDs
vcfDT[, ROW.ID:=1:nrow(vcfDT)]
# Iterate over the chunks
formatDat <- foreach(i=chunkSt, .combine='rbind') %dopar% {
require(data.table); require(tidyverse)
i2j <- i:(i + numChunks - 1)
i2j <- i2j[i2j<=maxRows]
xx <- vcfDT[i2j,]
yy <- t(xx[, strsplit(DATA, ':')])
yy[which(yy=='.')] <- NA
colnames(yy) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
yy <- as.data.table(yy)
yy$ROW.ID <- i2j
yy
}
# End cluster
stopCluster(clust)
# Combine data table and the parsed format data
vcfDT <- left_join(
vcfDT[, !c('FORMAT','DATA'), with=FALSE]
, formatDat, by='ROW.ID') %>%
.[, !'ROW.ID']
}
# Make sure DP, RO, and AO are integers
for(i in c('DP', 'RO', 'AO')){
if(i %in% colnames(vcfDT)){ vcfDT[[i]] <- as.integer(vcfDT[[i]]) }
}
# Attach header as an attribute, if specified.
if(keepComments==TRUE){
attr(vcfDT, 'vcf_comments') <- readLines(vcfFile, n=headPos-1)
}
# Attach info as an attribute if, if specified.
if(keepInfo==TRUE){
attr(vcfDT, 'vcf_info') <- vcfInfo
}
# Finish
cat('All done! <3', '\n')
readVcf1 <- vcf2DT(vcfFile=vcfPath)
#' VCF file to data table
#'
#' Reads a VCF file and converts to a long format data table.
#'
#' @param vcfFile Character: The path to the input VCF file.
#'
#' @param dropCols Character: Vector of column names from the VCF that you
#' want to drop from the data table. Default = \code{NULL}.
#' Only relevant when argument \code{flip==FALSE}.
#'
#' @param keepComments Logical: Should the VCF comments be kept?
#' Default = \code{FALSE}. See Details for parameterisation.
#'
#' @param keepInfo Logical: Should the VCF info for each locus be kept?
#' Default = \code{FALSE}.
#'
#' @param numCores Integer: The number of cores to use. Default is 1.
#' Set \code{numCores > 1} to run in parallel.
#'
#' @param numChunks Integer: The number of data chunks to run when
#' running in parallel, i.e. \code{numCores > 1}. Default is 1000. Each chunk
#' is \code{numChunks} rows long.
#'
#' @details Firstly, it should be noted that while data tables are a really
#' excellent way of handling genotype and sequence read information in R,
#' they are not necessarily the most efficient way to do so. Importing VCFs
#' as data table (or the reverse, exporting data tables as VCFs), can take
#' a considerable amount of time if the number of loci and samples are large.
#' However, a bit of patience is worth it! \cr
#'
#' @return A \code{data.table} object is returned with all the columns contained in
#' the original VCF file with some additions:
#' \itemize{
#'     \item A column called \code{LOUCS} is generated. This is the concatenation of the
#'              \code{CHROM} and \code{POS} column to form a locus ID.
#'     \item A column called \code{SAMPLE} is generated. This contains the sample IDs that
#'              are the columns that follow the \code{FORMAT} column in the original VCF.
#'     \item The items in the original \code{FORMAT} column of the VCF are given their own columns.
#' } \cr
#' Note, for VCF files produced by Stacks, the $CHROM is given the same value
#' as the $ID column. \cr\cr
#' When \code{keepInfo==TRUE} and/or \code{keepComments==TRUE}, these are returned
#' as attributes. E.g., if the returned object is \code{vcfDT}, then you can
#' access Info and Comments (respectively) with: \code{attr(vcfDT, 'vcf_info')}
#' and \code{attr(vcfDT, 'vcf_comments')}.
#'
#' @references This & Riginos (2019) genomalicious: serving up a smorgasbord of
#' R functions for population genomic analyses. BioRxiv.
#'
#' @examples
#' # Create a link to raw external datasets in genomalicious
#' genomaliciousExtData <- paste0(find.package('genomalicious'), '/extdata')
#'
#' # This command here shows you the VCF file that comes with genomalicious
#' list.files(path=genomaliciousExtData, pattern='indseq.vcf')
#'
#' # Use this to create a path to that file
#' vcfPath <- paste0(genomaliciousExtData, '/data_indseq.vcf')
#'
#' # You can read the file in as lines to see what it
#' # looks like:
#' readLines(vcfPath)
#'
#' # Now read it in as a data table
#' readVcf1 <- vcf2DT(vcfFile=vcfPath)
#' readVcf1
#'
#' # Read in VCF, but drop some columns,
#' # and keep comments and info.
#' readVcf2 <- vcf2DT(vcfPath
#'    , dropCols=c('FILTER', 'ID')
#'    , keepComments=TRUE
#'    , keepInfo=TRUE)
#'
#' readVcf2
#'
#' attr(readVcf2, 'vcf_comments')
#' attr(readVcf2, 'vcf_info')
#'
#' # Run in parallel
#' readVcf3 <- vcf2DT(vcfPath
#'     , numCores=2
#'     , numChunks=10)
#'
#' @export
vcf2DT <- function(vcfFile, dropCols=NULL, keepComments=FALSE, keepInfo=FALSE
, numCores=1, numChunks=1000){
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# #### Libraries and assertions            ####
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
require(data.table); require(doParallel); require(tidyverse)
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# #### Code: VCF to data table             ####
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# What is the position of the header?
headPos <- grep('#CHROM', readLines(vcfFile), value=FALSE)
# Read file from header
cat('(1/4) Reading in VCF as a data table', sep='\n')
vcfDT <- fread(vcfFile, skip=headPos-1, sep='\t', header=TRUE)
# Adjust header
colnames(vcfDT) <- gsub(pattern='#', replace='', x=colnames(vcfDT))
# Generate a $LOCUS column, place at the start of the data table
cat('(2/4) Generating locus IDs', sep='\n')
vcfDT <- vcfDT[, paste(CHROM, POS, sep='_')] %>%
data.table(LOCUS=., vcfDT)
# Get the locus info as a vector and drop from data table
if(keepInfo==TRUE){
vcfInfo <- vcfDT$INFO
names(vcfInfo) <- vcfDT$LOCUS
}
vcfDT <- vcfDT[, !'INFO']
# Which columns are the sample? The ones after the FORMAT column.
sampCols <- (which(colnames(vcfDT)=='FORMAT')+1):ncol(vcfDT)
# Now convert the data from wide to long
cat('(3/4) Converting from wide to long format', sep='\n')
vcfDT <- melt(data=vcfDT, id.vars=1:(sampCols[1]-1), measure.vars=sampCols, variable.name='SAMPLE', value.name='DATA')
# Make sure SAMPLE is a character
vcfDT$SAMPLE <- as.character(vcfDT$SAMPLE)
# Add the $FORMAT data into the data table
cat('(4/4) Collecting and organising FORMAT data', sep='\n')
if(numCores==1){
# Split string for each row, this will return a wide DT so
# transpose back into long DT.
formatDat <- t(vcfDT[, strsplit(DATA, ':')])
# Give missing values NA
formatDat[which(formatDat=='.')] <- NA
# Label the columns
colnames(formatDat) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
# Combine with the main data table, drop the $FORMAT and $DATA columns
vcfDT <- cbind(vcfDT[, !c('FORMAT','DATA'), with=FALSE], as.data.table(formatDat))
} else if(numCores>1){
# Register the number of cores for parallel processing
clust <- makeCluster(numCores)
registerDoParallel(cl=clust)
# The start position of the data chunks
chunkSt <- seq(1, nrow(vcfDT), by=numChunks)
# The max number of rows
maxRows <- nrow(vcfDT)
# Make row IDs
vcfDT[, ROW.ID:=1:nrow(vcfDT)]
# Iterate over the chunks
formatDat <- foreach(i=chunkSt, .combine='rbind') %dopar% {
require(data.table); require(tidyverse)
i2j <- i:(i + numChunks - 1)
i2j <- i2j[i2j<=maxRows]
xx <- vcfDT[i2j,]
yy <- t(xx[, strsplit(DATA, ':')])
yy[which(yy=='.')] <- NA
colnames(yy) <- unlist(strsplit(vcfDT$FORMAT[1], ':'))
yy <- as.data.table(yy)
yy$ROW.ID <- i2j
yy
}
# End cluster
stopCluster(clust)
# Combine data table and the parsed format data
vcfDT <- left_join(
vcfDT[, !c('FORMAT','DATA'), with=FALSE]
, formatDat, by='ROW.ID') %>%
.[, !'ROW.ID']
}
# Make sure DP, RO, and AO are integers
for(i in c('DP', 'RO', 'AO')){
if(i %in% colnames(vcfDT)){ vcfDT[[i]] <- as.integer(vcfDT[[i]]) }
}
# Attach header as an attribute, if specified.
if(keepComments==TRUE){
attr(vcfDT, 'vcf_comments') <- readLines(vcfFile, n=headPos-1)
}
# Attach info as an attribute if, if specified.
if(keepInfo==TRUE){
attr(vcfDT, 'vcf_info') <- vcfInfo
}
# Finish
cat('All done! <3', '\n')
# Return the data.table, drop any columns if specified.
if(is.null(dropCols)){
return(vcfDT)
} else{
return(vcfDT[, !dropCols, with=FALSE])
}
}
readVcf1 <- vcf2DT(vcfFile=vcfPath)
readVcf1
readVcf2 <- vcf2DT(vcfPath
, dropCols=c('FILTER', 'ID')
, keepComments=TRUE
, keepInfo=TRUE)
readVcf2
attr(readVcf2, 'vcf_comments')
attr(readVcf2, 'vcf_info')
# Run in parallel
readVcf3 <- vcf2DT(vcfPath
, numCores=2
, numChunks=10)
readVcf3
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
roxygenise()
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
roxygenise()
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
roxygenise()
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
roxygenise()
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE)
library(genomalicious)
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
roxygenise()
library(genomalicious)
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
alle_df <- genoDT2alleleDF(data_4pops)
#' second allele for "locus1".
#'
#' @examples
#' data(data_4pops)
#'
#' data_4pops
#'
#' alle_df <- genoDT2alleleDF(data_4pops)
#'
#' @export
genoDT2alleleDF <- function(dat, sampCol='SAMPLE', locusCol='LOCUS', genoCol='GT'){
require(data.table); require(tidyverse)
if(sum(c(sampCol, locusCol, genoCol) %in% colnames(dat))!=3){
stop('One of arguments sampCol, locusCol, genoCol is not in dat. See ?genoDT2alleleDF')
}
if(class(dat$GT) %in% c('integer', 'numeric')){
dat$GT <- genoscore_converter(dat$GT)
}
# Unique loci
uniq_loci <- unique(dat$LOCUS)
# Convert data table to wide matrix of genotypes
mat <- DT2Mat_genos(dat, 'SAMPLE', 'LOCUS', 'GT')
# Create the allele data frame.
# Iterate over loci.
alleDF <- lapply(uniq_loci, function(loc){
# Get genotypes for a locus
gen <- mat[,loc]
# Split the genotypes by '/', unlist, convert to integer,
# then convert to 2 column matrix
alle <- strsplit(gen, split='/') %>%
unlist() %>%
as.integer() %>%
matrix(., ncol=2, byrow=TRUE)
# Colnames
colnames(alle) <- paste(loc, 1:2, sep='_')
# Return
return(alle)
}) %>%
do.call('cbind', .) %>%
as.data.frame() %>%
data.frame(SAMPLE=rownames(mat), .)
return(alleDF)
}
data(data_4pops)
data_4pops
alle_df <- genoDT2alleleDF(data_4pops)
library(genomalicious)
alle_df <- genoDT2alleleDF(data_4pops)
alle_df[1:4, 1:6]
roxygenise(clean=TRUE) # Sometimes this throws an error?
roxygenise()
library(genomalicious)
install.packages('gridExtra', 'pbapply', 'car')
install.packages(c('gridExtra', 'pbapply', 'car'))
install.packages(c('devEMF'))
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("qvalue")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("qvalue")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
?BiocManager::install("qvalue")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
?BiocManager::install("qvalue", update=FALSE)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("qvalue", update=FALSE)
library(genomalicious)
library(genomalicious)
# CODE FOR BUILDING PACKAGE #
# Good website:
#   http://tinyheero.github.io/jekyll/update/2015/07/26/making-your-first-R-package.html
# Developer libraries
libs <- c('devtools', 'roxygen2', 'testthat', 'knitr', 'data.table', 'tidyverse')
for(L in libs){require(L, character.only=TRUE)}
# Make documents
roxygenise(clean=TRUE) # Sometimes this throws an error?
roxygenise()
library(genomalicious)
